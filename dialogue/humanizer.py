# dialogue/humanizer.py
import re
import random
from dataclasses import dataclass

EMOJI_RE = re.compile(r"[üôÇüòâ‚ù§Ô∏èüëçüî•üòÇüòÖüòäü§£üò≠‚ú®ü§îüëèüëåüí™üåüü§∑‚Äç‚ôÇÔ∏èü§∑‚Äç‚ôÄÔ∏èü•≤üôÉüòåüòçü§ó]", re.UNICODE)
WORD_RE = re.compile(r"\w+", re.UNICODE)

# –ü–æ—Ä–æ–≥ ¬´–∫–æ—Ä–æ—Ç–∫–æ–≥–æ¬ª —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π, —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é)
_SHORT_LEN = 40


@dataclass
class SpeechProfile:
    avg_words: float = 9.0     # —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    q_ratio: float = 0.2       # –¥–æ–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤
    emoji_ratio: float = 0.05  # –¥–æ–ª—è —ç–º–æ–¥–∑–∏ –Ω–∞ —Å–ª–æ–≤–æ
    short_bias: float = 0.6    # 0..1 ‚Äî —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –∫–æ—Ä–æ—Ç–∫–∏–º –æ—Ç–≤–µ—Ç–∞–º


# --- utils ---
def _count_words(s: str) -> int:
    return len(WORD_RE.findall(s or ""))


def _safe_float(x, default: float | None = None) -> float | None:
    try:
        return float(x) if x is not None else default
    except Exception:
        return default


def _ema(prev: float | None, x: float, alpha: float) -> float:
    if prev is None:
        return x
    return (1 - alpha) * prev + alpha * x


def _short_target_from_words(words: int) -> float:
    """
    –ú–∞–ø–ø–∏–Ω–≥ —á–∏—Å–ª–∞ —Å–ª–æ–≤ ‚Üí —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ short_bias –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0..1].
    –ß–µ–º –∫–æ—Ä–æ—á–µ —Ä–µ–ø–ª–∏–∫–∞, —Ç–µ–º –≤—ã—à–µ target.
    """
    if words <= 2:
        return 1.0
    if words <= 6:
        return 0.9
    if words <= 12:
        return 0.7
    if words <= 20:
        return 0.5
    if words <= 35:
        return 0.3
    return 0.15


# --- async profile API (—á–µ—Ä–µ–∑ memory_repo.kv) ---
async def update_user_profile(memory_repo, tg_user_id: int, text: str) -> SpeechProfile:
    w = _count_words(text)
    is_q = (text or "").strip().endswith("?")
    emojis = len(EMOJI_RE.findall(text or ""))

    # –ø—Ä–µ–∂–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    aw_prev = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "avg_words"))
    qr_prev = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "q_ratio"))
    er_prev = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "emoji_ratio"))
    sb_prev = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "short_bias"))

    # –æ–±–Ω–æ–≤–ª—è–µ–º EMA
    new_aw = _ema(aw_prev, float(w), alpha=0.25)
    new_qr = _ema(qr_prev, 1.0 if is_q else 0.0, alpha=0.20)
    density = emojis / max(1, w)
    new_er = _ema(er_prev, density, alpha=0.20)

    # short_bias ‚Äî —á–µ—Ä–µ–∑ EMA –∫ —Ü–µ–ª–µ–≤–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é, –∑–∞–≤–∏—Å—è—â–µ–º—É –æ—Ç –¥–ª–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è
    short_target = _short_target_from_words(w)
    new_sb = _ema(sb_prev, short_target, alpha=0.25)
    new_sb = max(0.0, min(1.0, new_sb))  # clamp

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    await memory_repo.set_kv(tg_user_id, "profile", "avg_words", f"{new_aw:.4f}")
    await memory_repo.set_kv(tg_user_id, "profile", "q_ratio", f"{new_qr:.4f}")
    await memory_repo.set_kv(tg_user_id, "profile", "emoji_ratio", f"{new_er:.4f}")
    await memory_repo.set_kv(tg_user_id, "profile", "short_bias", f"{new_sb:.4f}")
    await memory_repo.set_kv(tg_user_id, "profile", "last_len", str(len(text or "")))

    return SpeechProfile(avg_words=new_aw, q_ratio=new_qr, emoji_ratio=new_er, short_bias=new_sb)


async def get_user_profile(memory_repo, tg_user_id: int) -> SpeechProfile:
    aw = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "avg_words"), 9.0)
    qr = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "q_ratio"), 0.2)
    er = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "emoji_ratio"), 0.05)
    sb = _safe_float(await memory_repo.get_kv(tg_user_id, "profile", "short_bias"), 0.6)
    return SpeechProfile(
        avg_words=aw if aw is not None else 9.0,
        q_ratio=qr if qr is not None else 0.2,
        emoji_ratio=er if er is not None else 0.05,
        short_bias=sb if sb is not None else 0.6,
    )


# --- ¬´—Å–Ω—ç–ø¬ª-–æ—Ç–≤–µ—Ç—ã –±–µ–∑ LLM ---
HUMAN_SNIPS = {
    "ack": ["–∞–≥–∞", "—É–≥—É", "–æ–∫", "—è—Å–Ω–æ", "–ø–æ–Ω—è–ª–∞", "–≤–∏–∂—É", "—Å–ª—ã—à–Ω–æ", "–Ω–æ—Ä–º"],
    "pos": ["–∫—Ä—É—Ç–æ", "–∫–ª–∞—Å—Å", "–æ—Ç–ª–∏—á–Ω–æ", "–∑–≤—É–∫ —Ç–æ–ø", "–º–∏–ª–æ", "–Ω—Ä–∞–≤–∏—Ç—Å—è"],
}


def maybe_snap_reply(user_text: str, *, profile: SpeechProfile, last_assistant: str = "") -> str | None:
    txt = (user_text or "").strip()
    if txt.endswith("?"):
        return None  # –Ω–∞ –≤–æ–ø—Ä–æ—Å ‚Äî –Ω–µ ¬´—É–≥—É¬ª
    if len(last_assistant.split()) <= 3:
        return None  # –¥–≤–∞ ¬´—Å–Ω—ç–ø–∞¬ª –ø–æ–¥—Ä—è–¥ –Ω–µ–ª—å–∑—è

    w = _count_words(txt)

    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ short_bias –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    ack_p = 0.15 + 0.25 * float(profile.short_bias)  # 0.15..0.40
    pos_p = 0.20 + 0.15 * float(profile.short_bias)  # 0.20..0.35

    if w <= 2 and random.random() < ack_p:
        return random.choice(HUMAN_SNIPS["ack"])

    if w <= 5 and re.search(r"\b(–∫—Ä—É—Ç–æ|–∫–ª–∞—Å—Å|—Å—É–ø–µ—Ä|–Ω—Ä–∞–≤–∏—Ç|–æ–∫)\b", txt, re.IGNORECASE):
        if random.random() < pos_p:
            return random.choice(HUMAN_SNIPS["pos"])

    return None
